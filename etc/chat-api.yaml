Name: chat-rag
Host: 0.0.0.0
Port: 8888

# Logging configuration
Log:
  LogFilePath: "logs/"
  LokiEndpoint: "http://localhost:3100/loki/api/v1/push"
  LogScanIntervalSec: 10
  EnableClassification: false
  ClassifyModel: "gpt-oss-120b"

# Context Compression
ContextCompressConfig:
  EnableCompress: false
  TokenThreshold: 100_000
  SummaryModel: "qwen2.5-coder-32b"
  SummaryModelTokenThreshold: 64_000
  RecentUserMsgUsedNums: 3

PreciseContextConfig:
  EnableEnvDetailsFilter: true

# Department configuration
DepartmentApiEndpoint: "http://localhost:1234/work_id?work_id="

# Models supported by function calling
LLM:
  # Endpoint: "https://zgsm.sangfor.com/chat-rag/api/v1/chat/completions"
  Endpoint: "http://127.0.0.1:30616/v1/chat/completions"
  # Endpoint: "http://127.0.0.1:32325/model/glm-4.5-fp8/v1/chat/completions"
  FuncCallingModels:
    - "deepseek-v3"
    - "qwen3*"
    - "claude*"

Redis:
  Addr: "127.0.0.1:6379"

# Semantic API configuration
Tools:
  SemanticSearch:
    SearchEndpoint: "http://123.58.64.57:30080/codebase-embedder/api/v1/search/semantic"
    ApiReadyEndpoint: "http://123.58.64.57:30080/codebase-embedder/api/v1/embeddings/summary"
    TopK: 50
    ScoreThreshold: 0.7
  DefinitionSearch:
    SearchEndpoint: "http://127.0.0.1:9001/codebase-indexer/api/v1/search/definition"
    ApiReadyEndpoint: "http://127.0.0.1:9001/codebase-indexer/api/v1/index/summary"
  ReferenceSearch:
    SearchEndpoint: "http://127.0.0.1:9001/codebase-indexer/api/v1/calgraph"
    ApiReadyEndpoint: "http://127.0.0.1:9001/codebase-indexer/api/v1/index/summary"
  KnowledgeSearch:
    SearchEndpoint: "http://127.0.0.1:9001/codebase-embedder/api/v1/search/document"
    ApiReadyEndpoint: "http://127.0.0.1:9001/codebase-embedder/api/v1/documents/summary"
    TopK: 20
    ScoreThreshold: 0.7